@Library('pcloud-jenkins-library') _
//Define global variables
env.DISTRO = ""
def TIMEOUT_SEC
def TIMEOUT_MIN
def E2E_SUMMARY
def ERROR_MESSAGE
def clusterInfoFields = [:]
def clusterInfo = [:]
int FAILS_PER_THRESHOLD
int UNSTALE_PER_THRESHOLD
boolean INFRA_ISSUE = false
env.BASTION_IP = ""

pipeline {
    agent {
        dockerfile {
            dir 'images/powervs'
            additionalBuildArgs '--force-rm	--no-cache'
            args '-v /etc/resolv.conf:/etc/resolv.conf'
            label 'daily-x86_64'
        }
    }
    environment {
        //users and credentials. All must be defined in Jenkins Credentials
        GITHUB_USER = credentials('GITHUB_USER')
        TF_VAR_user_name = credentials('GITHUB_USER')
        DOCKER_USER = credentials('DOCKER_USER')
        ARTIFACTORY_USER = credentials('ARTIFACTORY_USER')
        TF_VAR_repo_user = credentials('GITHUB_USER')
        TF_VAR_password = credentials('TF_VAR_password')
        IBMCLOUD_API_KEY = credentials('IBMCLOUD_API_KEY')
        GITHUB_TOKEN = credentials('GITHUB_TOKEN')
        ARTIFACTORY_TOKEN = credentials('ARTIFACTORY_TOKEN')
        TF_VAR_offline_remote_password = credentials('ARTIFACTORY_TOKEN')
        REDHAT_USERNAME = credentials('REDHAT_USERNAME')
        REDHAT_PASSWORD = credentials('REDHAT_PASSWORD')
        PUBLIC_GITHUB_USER = credentials('PUBLIC_GITHUB_USER')
        PUBLIC_GITHUB_TOKEN = credentials('PUBLIC_GITHUB_TOKEN')


        //Env constants
        TERRAFORM_VER = "0.13.4"
        IBM_CLOUD_REGION = "us-east"
        IBM_CLOUD_ZOME = "us-east"
        SERVICE_INSTANCE_ID = "8aec6256-b197-4fe5-afcf-7507be7aa77b"

        BASTION_MEMORY = "8"
        BASTION_PROCESSORS = ".5"

        BOOTSTRAP_MEMORY = "16"
        BOOTSTRAP_PROCESSORS = ".5"

        MASTER_MEMORY = "16"
        MASTER_PROCESSORS = ".5"
        NUM_OF_MASTERS = "3"

        WORKER_MEMORY = "16"
        WORKER_PROCESSORS = ".5"
        NUM_OF_WORKERS = "2"

        BASTION_IMAGE_NAME = "rhel-82-10072020-001"
        RHCOS_IMAGE_NAME = "rhcos-45-09242020-001"

        SYSTEM_TYPE = "s922"
        NETWORK_NAME = "ocp-net"
        RHEL_USERNAME = "root"
        RHEL_SMT = "4"
        CLUSTER_DOMAIN = "redhat.com"
        INSTANCE_NAME = "ltccci"

        ENABLE_LOCAL_REGISTRY = "false"
        LOCAL_REGISTRY_IMAGE = "docker.io/ibmcom/registry-ppc64le:2.6.2.5"

        SETUP_SQUID_PROXY = "true"

        // Bellow 4 variables are not used. Disabled in template
        HELPERNODE_REPO = "https://github.com/RedHatOfficial/ocp4-helpernode"
        HELPERNODE_TAG = "5eab3db53976bb16be582f2edc2de02f7510050d"
        INSTALL_PLAYBOOK_REPO = "https://github.com/ocp-power-automation/ocp4-playbooks"
        INSTALL_PLAYBOOT_TAG = "d2509c4b4a67879daa6338f68e8e7eb1e15d05e2"

        UPGRADE_IMAGE = ""
        UPGRADE_PAUSE_TIME = ""
        UPGRADE_DELAY_TIME = ""

        TIMEOUT = "0"
        OCP_RELEASE = "4.5"

        //e2e specific variables
        ENABLE_E2E_TEST = "true"
        E2E_GIT = "https://github.com/openshift/origin"
        E2E_BRANCH="release-${OCP_RELEASE}"
        E2E_EXCLUDE_LIST = "https://raw.github.ibm.com/redstack-power/e2e-exclude-list/${OCP_RELEASE}-powervm/ocp${OCP_RELEASE}_power_blacklist.txt"
        GOLANG_TARBALL = "https://dl.google.com/go/go1.13.12.linux-ppc64le.tar.gz"

        //Makefile variables
        TERRAFORM_FORCE_KEYPAIR_CREATION = "0" //For not using build-barnes
        OPENSHIFT_POWERVS_GIT_TF_DEPLOY_BRANCH="release-4.5" //The downlod branch

        TARGET = "deploy-openshift4-powervs"
        TERMPLATE_FILE = ".${TARGET}.tfvars.template"

        //To pick build-harness . Remove once the Makefile.openshift_pvc upstreamed
        BUILD_HARNESS_ORG="powercloud-cicd"
        //BUILD_HARNESS_BRANCH="devel"
        POWERVS = true
        WAIT_FOR_DEBUG = "6"
	 }

    stages {
        stage('Clone ansible extra') {
            steps {
                checkout([$class: 'GitSCM', branches: [[name: '*/master']], doGenerateSubmoduleConfigurations: false, extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'ansible_extra'], [$class: 'CleanBeforeCheckout'], [$class: 'CloneOption', depth: 0, noTags: false, reference: '', shallow: false, timeout: 20]], submoduleCfg: [], userRemoteConfigs: [[url: 'git@github.ibm.com:redstack-power/ocp4_ansible_extras.git', credentialsId: 'ibm-github']]])
            }
        }
        stage('pull artifact') {
            steps {
                script {
                    step([  $class: 'CopyArtifact',
                    filter: 'latest-4.5-build.txt',
                    fingerprintArtifacts: true,
                    projectName: 'mirror-openshift-release',
                    target: 'artifactory',
                    selector: lastSuccessful()
                    ])
                }
            }
        }
        //Checkout the installer git repo
        stage('Prepare Teraform Template') {
            steps {
                script {
                    ansiColor('xterm') {
                        echo ""
                    }
                    try
                    {
                        env.OPENSHIFT_IMAGE = ""
                        env.OCP_RELEASE_TAG = ""
                        if (fileExists('artifactory/latest-4.5-build.txt')) {
                            env.OPENSHIFT_IMAGE = readFile 'artifactory/latest-4.5-build.txt'
                            env.OPENSHIFT_IMAGE = env.OPENSHIFT_IMAGE.trim()
                            env.OCP_RELEASE_TAG = env.OPENSHIFT_IMAGE.split(":")[1].trim()
                        }
                        env.OPENSHIFT_INSTALL_TARBALL=getOpenshiftBuild(OCP_RELEASE)
                        if ("${env.OPENSHIFT_INSTALL_TARBALL}" == "null" )
                        {
                            echo "Unable to find openshift install tarball. falling back to default"
                            env.OPENSHIFT_INSTALL_TARBALL="https://mirror.openshift.com/pub/openshift-v4/ppc64le/clients/ocp/4.5.5/openshift-install-linux.tar.gz"
                        }
                        env.OPENSHIFT_CLIENT_TARBALL=getOpenshiftClient(OCP_RELEASE)
                        if ("${env.OPENSHIFT_CLIENT_TARBALL}" == "null")
                        {
                            env.OPENSHIFT_CLIENT_TARBALL="https://mirror.openshift.com/pub/openshift-v4/ppc64le/clients/ocp/4.5.5/openshift-client-linux.tar.gz"
                        }
                        env.OPENSHIFT_CLIENT_TARBALL_AMD64=getOpenshiftClientAMD(OCP_RELEASE)
                        if ("${env.OPENSHIFT_CLIENT_TARBALL_AMD64}" == "null")
                        {
                            env.OPENSHIFT_CLIENT_TARBALL_AMD64="https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.5.5/openshift-client-linux.tar.gz"
                        }
                    }
                    catch (err)
                    {
                        echo 'Error ! Template prepration failed !'
                        getArtifactsAndCleanOcp4(env.AUTH_URL)
                        throw err
                    }
                }
            }
        }
        stage('Setup terraform plugin') {
            steps {
                script {
                    ansiColor('xterm') {
                        echo ""
                    }
                    try {
                        sh '''
                        echo ' get the plugin from artifactory repo !'
                        wget https://github.com/IBM-Cloud/terraform-provider-ibm/releases/download/v1.9.0/linux_amd64.zip
                        mkdir -p ~/.terraform.d/plugins/linux_amd64/
                        unzip linux_amd64.zip -d ~/.terraform.d/plugins/linux_amd64/
                        '''
                        }
                    catch (err) {
                        echo 'Error ! ENV setup failed!'
                        getArtifactsAndCleanOcp4(env.AUTH_URL)
                        throw err
                    }
                }
            }
        }
        stage('Initilize Environment') {
            steps {
                script {
                    ansiColor('xterm') {
                        echo ""
                    }
                    try {
                        sh '''
                        echo 'Initializing supporting repos and keys !'

                        cd ${WORKSPACE}/deploy
                        make init
                        make keys
                        make setup-dependencies
                        '''
                        }
                    catch (err) {
                        echo 'Error ! ENV setup failed!'
                        getArtifactsAndCleanOcp4(env.AUTH_URL)
                        throw err
                    }
                }
            }
        }
        stage('Deploy OCP Cluster') {
            steps {
                script {
                    ansiColor('xterm') {
                        echo ""
                    }
                    try {
                        sh '''
                        echo 'Deploying Cluster!'
                        export TF_VAR_offline_remote_password=$TF_VAR_password
                        cd ${WORKSPACE}/deploy
                        make $TARGET || true
                        retries=0
                        until [ "$retries" -ge 3 ]
                        do
                                if [ "$retries" -eq 2 ]; then
                                        make $TARGET:redeploy
                                        sleep 60
                                else
                                        make $TARGET:redeploy || true
                                fi
                                retries=$((retries+1))
                                sleep 10
                        done
                        '''
                        env.BASTION_IP=sh(returnStdout: true, script: "cd ${WORKSPACE}/deploy && make terraform:output TERRAFORM_DIR=.${TARGET} TERRAFORM_OUTPUT_VAR=bastion_public_ip").trim()
                        }
                    catch (err) {
                        TIMEOUT_HRS =  WAIT_FOR_DEBUG.toInteger()
                        if ( TIMEOUT_HRS != 0 )
                        {
                            TIMEOUT_SEC=TIMEOUT_HRS*60*60
                        }
                        echo "HOLDING THE CLUSTER FOR DEBUGGING, FOR ${TIMEOUT_HRS} MINUTES"
                        sleep TIMEOUT_SEC
                        throw err
                    }
                }
            }
        }
        stage('Setup and run ansible extra') {
            steps {
                script {
                    ansiColor('xterm') {
                        echo ""
                    }
                    try {
                       sh '''
                        echo 'Creating var.yaml'
                        rm -rf ~/.ansible
                        ansible all -m setup -a 'gather_subset=!all'
                        cd ${WORKSPACE}/ansible_extra
                        cp examples/e2e_vars.yaml vars.yaml
                        sed -i "s|e2e_tests_enabled:.*$|e2e_tests_enabled: true|g" vars.yaml
                        sed -i "s|e2e_tests_git:.*$|e2e_tests_git: ${E2E_GIT}|g" vars.yaml
                        sed -i "s|e2e_tests_git_branch:.*$|e2e_tests_git_branch: ${E2E_BRANCH}|g" vars.yaml
                        sed -i "s|e2e_tests_exclude_list_url:.*$|e2e_tests_exclude_list_url: ${E2E_EXCLUDE_LIST}|g" vars.yaml
                        sed -i "s|golang_tarball:.*$|golang_tarball: ${GOLANG_TARBALL}|g" vars.yaml
                        sed -i "s|github_token:.*$|github_token: ${GITHUB_TOKEN}|g" vars.yaml
                        cat vars.yaml
                        cp examples/inventory .
                        sed -i "s|localhost|${BASTION_IP}|g" inventory
                        sed -i 's/ansible_connection=local/ansible_connection=ssh/g' inventory
                        sed -i "s|ssh|ssh ansible_ssh_private_key_file=${WORKSPACE}/deploy/id_rsa|g" inventory
                        cat inventory
                        echo "[ssh_connection]" >> ansible.cfg
                        echo "ssh_args = -C -o ControlMaster=auto -o ControlPersist=120m -o ServerAliveInterval=30" >> ansible.cfg
                        cat ansible.cfg
                        ansible-playbook  -i inventory -e @vars.yaml playbooks/main.yml
                       # cd ../
                       # tar -czvf ansible_extra.tar.gz ansible_extra
                       # scp -o 'StrictHostKeyChecking no' -i ${WORKSPACE}/deploy/id_rsa ansible_extra.tar.gz root@${BASTION_IP}:
                       # ssh -o 'StrictHostKeyChecking no' -i ${WORKSPACE}/deploy/id_rsa root@${BASTION_IP} tar -zxvf ansible_extra.tar.gz
                       # ssh -o 'StrictHostKeyChecking no' -i ${WORKSPACE}/deploy/id_rsa root@${BASTION_IP} "cd ansible_extra ; ansible-playbook  -i inventory -e @vars.yaml playbooks/main.yml -vvv"
                        '''
                    }
                    catch (err) {
                        echo 'Error ! ENV setup failed!'
                        getArtifactsAndCleanOcp4(env.AUTH_URL)
                        throw err
                    }
                }
            }
        }
        stage('Gather pprof and prometheus data') {
            steps {
                script {
                    ansiColor('xterm') {
                        echo ""
                    }
                    try {
                        sh '''
                           ssh -o 'StrictHostKeyChecking no' -i ${WORKSPACE}/deploy/id_rsa root@${BASTION_IP} "oc get --raw /debug/pprof/profile --as=system:admin" > cpu-pre.pprof || true
                           ssh -o 'StrictHostKeyChecking no' -i ${WORKSPACE}/deploy/id_rsa root@${BASTION_IP} "oc get --raw /debug/pprof/heap --as=system:admin" > heap-pre.pprof || true
                           ssh -o 'StrictHostKeyChecking no' -i ${WORKSPACE}/deploy/id_rsa root@${BASTION_IP} "oc --insecure-skip-tls-verify exec -n openshift-monitoring prometheus-k8s-0 -- tar cvzf - -C /prometheus . " > prometheus.tar.gz || true
                        '''
                        }
                    catch (err) {
                        echo 'Error ! Tearing off the cluster !'
                        getArtifactsAndCleanOcp4(env.AUTH_URL)
                        throw err
                    }
                }
            }
        }
    }
    post {
        always {
            getArtifactsAndCleanOcp4(env.AUTH_URL)
            archiveArtifacts allowEmptyArchive: true, artifacts: 'deploy/conformance-parallel-out.txt.tar.gz', fingerprint: true, onlyIfSuccessful: false
            archiveArtifacts allowEmptyArchive: true, artifacts: 'deploy/summary.txt', fingerprint: true, onlyIfSuccessful: false
            archiveArtifacts allowEmptyArchive: true, artifacts: 'deploy/powervc.tfvars', fingerprint: true, onlyIfSuccessful: false
            archiveArtifacts allowEmptyArchive: true, artifacts: 'cpu-pre.pprof', fingerprint: true, onlyIfSuccessful: false
            archiveArtifacts allowEmptyArchive: true, artifacts: 'heap-pre.pprof', fingerprint: true, onlyIfSuccessful: false
            archiveArtifacts allowEmptyArchive: true, artifacts: 'prometheus.tar.gz', fingerprint: true, onlyIfSuccessful: false
            script {
                if (fileExists('deploy/summary.txt')) {
                    E2E_SUMMARY = readFile 'deploy/summary.txt'
                    if (E2E_SUMMARY.contains('fail')) {
                        E2E_SUMMARY = E2E_SUMMARY.trim()
                        STR = E2E_SUMMARY.split(',')
                        FAILS = STR[0].split()
                        PASS = STR[1].split()
                        SKIP = STR[2].split()
                        TOTAL = FAILS[0].toInteger() + PASS[0].toInteger() + SKIP[0].toInteger()
                        FAILS_PER_THRESHOLD = (TOTAL - SKIP[0].toInteger())
                        UNSTALE_PER_THRESHOLD = (TOTAL - SKIP[0].toInteger()) * 0.05 - 1
                    }
                    else {
                        E2E_SUMMARY = E2E_SUMMARY.trim()
                        STR = E2E_SUMMARY.split(',')
                        PASS = STR[0].split()
                        SKIP = STR[1].split()
                        TOTAL = PASS[0].toInteger() + SKIP[0].toInteger()
                        FAILS_PER_THRESHOLD = (TOTAL - SKIP[0].toInteger())
                        UNSTALE_PER_THRESHOLD = (TOTAL - SKIP[0].toInteger()) * 0.05 - 1
                    }
                }
                def logContent = Jenkins.getInstance().getItemByFullName(env.JOB_NAME).getBuildByNumber(Integer.parseInt(env.BUILD_NUMBER)).logFile.text
                def logContent_modified=logContent.toLowerCase()
                def infra_errors = readFile 'files/infra-issues.txt'
                infra_errors.split('\n').each { line ->
                   line1=line.toLowerCase()
                    if ( line1  != null) {
                        if (logContent_modified.contains(line1)){
                            INFRA_ISSUE = true
                            ERROR_MESSAGE = line1
                        }
                    }
                }
                if ( env.OPENSHIFT_IMAGE != ""  ) {
                    env.OPENSHIFT_INSTALL_TARBALL = env.OPENSHIFT_IMAGE
                }
                if ( fileExists('deploy/junit_e2e.xml')) {
                    sh '''
                    sed -i 's|^<testsuite |<testsuite errors="0"  |' deploy/junit_e2e.xml
                    sed  -i  's|<property name=.*property>||'  deploy/junit_e2e.xml
                    '''
                    step([$class: 'XUnitPublisher', thresholds: [[$class: 'FailedThreshold', failureThreshold: FAILS_PER_THRESHOLD.toString(), unstableThreshold: '10' ]], tools: [[$class: 'JUnitType', pattern: 'deploy/junit_e2e.xml']]])
                }
                else
                {
                    step([$class: 'JUnitResultArchiver', allowEmptyResults: true,  testResults: 'hack/dummay-test-summary.xml'])
                    currentBuild.result = 'FAILURE'
                }
                clusterInfo['ocp_build'] = env.OPENSHIFT_INSTALL_TARBALL
                clusterInfo['master_node_cpu'] = "${MASTER_PROCESSORS}"
                clusterInfo['master_node_mem'] = "${MASTER_MEMORY}"
                clusterInfo['worker_node_cpu'] = "${WORKER_PROCESSORS}"
                clusterInfo['worker_node_mem'] = "${WORKER_MEMORY}"
                clusterInfo['cluster_masters'] = "${NUM_OF_MASTERS}"
                clusterInfo['cluster_workers'] = "${NUM_OF_WORKERS}"
                clusterInfo['system_type']     = "${SYSTEM_TYPE}"

                clusterInfoFields['clusterinfo'] = clusterInfo

                if ( ! INFRA_ISSUE ) {
                    step([$class: 'InfluxDbPublisher', selectedTarget: 'influxdbmollypowervs', customDataMap: clusterInfoFields])
                }
                else{
                    echo "Skipping this run from updating the dashboard database, as this is an infra related issue"
                    E2E_SUMMARY = ERROR_MESSAGE
                }
            notifyBySlackOcp4(currentBuild.result, env.OPENSHIFT_INSTALL_TARBALL, E2E_SUMMARY, env.RHCOS_IMAGE_NAME)
            cleanWs()
            }
        }
    }
}
